{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP_final_NN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FUlIl6lwLh6",
        "outputId": "8de56d1e-5ee1-48ca-849e-f7d69a98d9a3"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-16 12:42:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-16 12:42:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-16 12:42:38--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 51s  \n",
            "\n",
            "2021-02-16 12:49:30 (2.00 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD_tF5esxxuF",
        "outputId": "725ff372-077c-4b70-a3a6-06b53a564e0e"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J4CW68dqJua"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "import itertools\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7UixMu3_VTm",
        "outputId": "02ae81ed-1a94-4341-ef72-8e2b96d9bb4e"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "4W0OjZ83rW6Y",
        "outputId": "61a7009d-f9dc-4ddb-ffa1-f0b23bdaec1a"
      },
      "source": [
        "train_path = \"/content/drive/MyDrive/anlp_final/snli_1.0_dev.csv\"\n",
        "df = pd.read_csv(train_path)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>captionID</th>\n",
              "      <th>pairID</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>label3</th>\n",
              "      <th>label4</th>\n",
              "      <th>label5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>( ( Two women ) ( ( are ( embracing ( while ( ...</td>\n",
              "      <td>( ( The sisters ) ( ( are ( ( hugging goodbye ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS sisters)) (VP (VBP ...</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The sisters are hugging goodbye while holding ...</td>\n",
              "      <td>4705552913.jpg#2</td>\n",
              "      <td>4705552913.jpg#2r1n</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entailment</td>\n",
              "      <td>( ( Two women ) ( ( are ( embracing ( while ( ...</td>\n",
              "      <td>( ( Two woman ) ( ( are ( holding packages ) )...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NN woman)) (VP (VBP are...</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>Two woman are holding packages.</td>\n",
              "      <td>4705552913.jpg#2</td>\n",
              "      <td>4705552913.jpg#2r1e</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>( ( Two women ) ( ( are ( embracing ( while ( ...</td>\n",
              "      <td>( ( The men ) ( ( are ( fighting ( outside ( a...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS men)) (VP (VBP are)...</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The men are fighting outside a deli.</td>\n",
              "      <td>4705552913.jpg#2</td>\n",
              "      <td>4705552913.jpg#2r1c</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entailment</td>\n",
              "      <td>( ( ( Two ( young children ) ) ( in ( ( ( ( ( ...</td>\n",
              "      <td>( ( ( Two kids ) ( in ( numbered jerseys ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (JJ young) (NNS chil...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS kids)) (PP (IN ...</td>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
              "      <td>2407214681.jpg#0</td>\n",
              "      <td>2407214681.jpg#0r1e</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>( ( ( Two ( young children ) ) ( in ( ( ( ( ( ...</td>\n",
              "      <td>( ( ( Two kids ) ( at ( a ballgame ) ) ) ( ( w...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (JJ young) (NNS chil...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS kids)) (PP (IN ...</td>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids at a ballgame wash their hands.</td>\n",
              "      <td>2407214681.jpg#0</td>\n",
              "      <td>2407214681.jpg#0r1n</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gold_label  ...         label5\n",
              "0        neutral  ...        neutral\n",
              "1     entailment  ...     entailment\n",
              "2  contradiction  ...  contradiction\n",
              "3     entailment  ...     entailment\n",
              "4        neutral  ...     entailment\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJUxNW3uuCLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4703019f-12b5-4858-aafd-f79956d6724c"
      },
      "source": [
        "df = df[['sentence1', 'sentence2', 'gold_label']]\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The sisters are hugging goodbye while holding ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>Two woman are holding packages.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The men are fighting outside a deli.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids at a ballgame wash their hands.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ...     gold_label\n",
              "0  Two women are embracing while holding to go pa...  ...        neutral\n",
              "1  Two women are embracing while holding to go pa...  ...     entailment\n",
              "2  Two women are embracing while holding to go pa...  ...  contradiction\n",
              "3  Two young children in blue jerseys, one with t...  ...     entailment\n",
              "4  Two young children in blue jerseys, one with t...  ...        neutral\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfB8B4EfSbsZ",
        "outputId": "570e1840-07cf-4f00-dd2c-455353033c18"
      },
      "source": [
        "df['gold_label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       3329\n",
              "contradiction    3278\n",
              "neutral          3235\n",
              "-                 158\n",
              "Name: gold_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7daXAgD4S8KP"
      },
      "source": [
        "def encode_label(df):\n",
        "  df = df[['sentence1', 'sentence2', 'gold_label']]\n",
        "  lb = LabelEncoder()\n",
        "  df = df[(df['gold_label'] == 'neutral') | (df['gold_label'] == 'contradiction') | (df['gold_label'] == 'entailment')]\n",
        "  df['labels'] = lb.fit_transform(df['gold_label'])\n",
        "  classes_names = lb.classes_\n",
        "  df.drop('gold_label', axis = 1,  inplace= True)\n",
        "  return df, classes_names"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sscdzinTtx0"
      },
      "source": [
        "df, classes_names = encode_label(df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uyc5Hg2sT0nU",
        "outputId": "683efe90-73c0-4f68-e757-5ee7d4a87c14"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The sisters are hugging goodbye while holding ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>Two woman are holding packages.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The men are fighting outside a deli.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids at a ballgame wash their hands.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ... labels\n",
              "0  Two women are embracing while holding to go pa...  ...      2\n",
              "1  Two women are embracing while holding to go pa...  ...      1\n",
              "2  Two women are embracing while holding to go pa...  ...      0\n",
              "3  Two young children in blue jerseys, one with t...  ...      1\n",
              "4  Two young children in blue jerseys, one with t...  ...      2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K0i2VGDT7yD",
        "outputId": "23df89b8-c417-4349-edb8-1698390d59bf"
      },
      "source": [
        "classes_names"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['contradiction', 'entailment', 'neutral'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ2UFl26yWmO"
      },
      "source": [
        "##Embedding Things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1eSB9NoyZNE"
      },
      "source": [
        "def Embedding_dict(path):\n",
        "  emb_dct = {}\n",
        "  with open(path) as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "      emb_dct[word] = coefs\n",
        "  print(f\"Number of words found are {len(emb_dct)}\")\n",
        "  return emb_dct"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLpxydm-zq-W"
      },
      "source": [
        "def create_dataset(df, dct, func = 'sum', emb_dim = 300):\n",
        "  embedding_matrix = np.zeros((df.shape[0], 2*emb_dim))\n",
        "  hit = 0\n",
        "  miss = 0\n",
        "  for i, (s1, s2) in enumerate(zip(df['sentence1'], df['sentence2'])):\n",
        "    vec1 = []\n",
        "    vec2 = []\n",
        "    s1 = s1.lower()\n",
        "    s2 = s2.lower()\n",
        "    s1 = word_tokenize(s1)\n",
        "    s2 = word_tokenize(s2)\n",
        "    for w1, w2 in list(itertools.zip_longest(s1, s2, fillvalue='foo')):\n",
        "      if w1 != \"foo\":\n",
        "        check1 = dct.get(w1)\n",
        "        if check1 is not None:\n",
        "          vec1.append(check1)\n",
        "          hit+=1\n",
        "        else:\n",
        "          miss+=1\n",
        "        \n",
        "      if w2 != \"foo\":\n",
        "        check1 = dct.get(w2)\n",
        "        if check1 is not None:\n",
        "          vec2.append(check1)\n",
        "          hit+=1\n",
        "        else:\n",
        "          miss+=1\n",
        "    ##\n",
        "    vec1 = np.asarray(vec1)\n",
        "    vec2 = np.asarray(vec2)\n",
        "    if func == \"sum\":\n",
        "      vec1 = np.sum(vec1, axis = 0)\n",
        "      vec2 = np.sum(vec2, axis = 0)\n",
        "    if func == \"mean\":\n",
        "      vec1 = np.mean(vec1, axis = 0)\n",
        "      vec2 = np.mean(vec2, axis = 0)\n",
        "    #print(\"vec1 \", vec1.shape, \"vec2 shape \", vec2.shape, \"i is \", i)\n",
        "    embedding_matrix[i, :] = np.concatenate((vec1, vec2))\n",
        "  ##\n",
        "  print(f\"The number of hits are {hit} and the number of miss are {miss}\")\n",
        "  labels = df['labels'].values\n",
        "  return embedding_matrix, labels    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dttDavPwARZY"
      },
      "source": [
        "class simple_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(simple_model, self).__init__()\n",
        "    # self.embedding_matrix = embedding_matrix\n",
        "    # self.labels = labels\n",
        "    self.fc1 = nn.Linear(600, 256)\n",
        "    self.fc2 = nn.Linear(256, 64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "  def forward(self, embedding_matrix):\n",
        "    x = self.fc1(embedding_matrix)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqkNZ8ZuE5zz"
      },
      "source": [
        "def train(model, embedding_matrix, labels, batch_size = 32, lr = 0.007, epochs = 4):\n",
        "  model.train()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
        "  #model.zero_grad()\n",
        "  for epoch in range(epochs):\n",
        "    l = 0\n",
        "    for i in range(embedding_matrix.shape[0]//batch_size):\n",
        "      optimizer.zero_grad()\n",
        "      inp = embedding_matrix[i*batch_size: (i*batch_size + batch_size), :]\n",
        "      lab = torch.from_numpy(labels[i*batch_size: (i*batch_size + batch_size)])\n",
        "      out = model(torch.from_numpy(inp).float())\n",
        "      loss = criterion(out, lab)\n",
        "      l += loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "    if epoch%10 == 0:\n",
        "      print(\"loss is \", loss)\n",
        "      print(f\"for epoch {epoch} loss is {l}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLoQjMBl7SfN"
      },
      "source": [
        "model = simple_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PyHMKSRQcdw"
      },
      "source": [
        "train(model, embedding_matrix, labels, lr = 0.005, epochs = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y_ZQPCQMHua"
      },
      "source": [
        "ypredt = model(torch.from_numpy(embedding_matrix).float())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3fVYP49MU5u"
      },
      "source": [
        "ypredt = torch.argmax(ypredt, dim = 1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LonTkVoJMiQg",
        "outputId": "8a72f1ab-5459-4225-8c49-6a0116c6c1a1"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 1, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9gUkFuwMj5k",
        "outputId": "8467974b-2b39-46a2-b613-e0c8a12757ee"
      },
      "source": [
        "ypredt == labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMyyijiHMcyR",
        "outputId": "52d6feeb-10fa-4af3-ce44-fe85ffe71375"
      },
      "source": [
        "np.sum(ypredt == labels)/len(ypredt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8984962406015038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66B_kVUW7G1f",
        "outputId": "371307f4-bb41-41ac-8e02-19db4a94fabe"
      },
      "source": [
        "# dct = Embedding_dict(\"/content/glove.6B.300d.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words found are 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it0f10nIOHjZ",
        "outputId": "32ab6603-ade0-4bdc-b9c6-aad4f81bb857"
      },
      "source": [
        "# embedding_matrix, labels = create_dataset(df, dct)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of hits are 211049 and the number of miss are 20614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJbGvisJD7AP"
      },
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/anlp_final/snli_1.0_test.csv\")\n",
        "df_test, class_test = encode_label(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7CT03ru6KmQF",
        "outputId": "ecacaa47-e8da-4ca5-fc13-5d923fd5a603"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church has cracks in the ceiling.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church is filled with song.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>A choir singing at a baseball game.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is young.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is very happy.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ... labels\n",
              "0  This church choir sings to the masses as they ...  ...      2\n",
              "1  This church choir sings to the masses as they ...  ...      1\n",
              "2  This church choir sings to the masses as they ...  ...      0\n",
              "3  A woman with a green headscarf, blue shirt and...  ...      2\n",
              "4  A woman with a green headscarf, blue shirt and...  ...      1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBktKVC_D1wO",
        "outputId": "24a04bf4-0965-40f6-9397-1bc1e4fff563"
      },
      "source": [
        "xte, yte = create_dataset(df_test, dct)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of hits are 229983 and the number of miss are 598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtjMJmu2KKbO",
        "outputId": "2f0013be-fe52-4548-aff7-7d275877ee5d"
      },
      "source": [
        "xte[:5,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.13825274, -1.14646089, -2.48438668, ..., -1.49156785,\n",
              "        -0.68954498,  0.13984601],\n",
              "       [-5.13825274, -1.14646089, -2.48438668, ..., -0.68161893,\n",
              "        -1.6593082 , -0.36632299],\n",
              "       [-5.13825274, -1.14646089, -2.48438668, ..., -0.93746603,\n",
              "        -1.24169397,  0.06316002],\n",
              "       [-2.2857213 , -0.36229506,  0.77572596, ...,  0.1158911 ,\n",
              "        -1.12795997,  0.78471696],\n",
              "       [-2.2857213 , -0.36229506,  0.77572596, ..., -0.4090839 ,\n",
              "        -0.66159904,  1.14149594]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWY0AxQHIyte"
      },
      "source": [
        "xte = torch.from_numpy(xte).float()\n",
        "yte =  torch.from_numpy(yte)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHoXczpgH4-L"
      },
      "source": [
        "ypred = model(xte)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOLjwlamKAqO",
        "outputId": "b2297850-5572-45e3-84d1-b1b2c32cdfb1"
      },
      "source": [
        "ypred[-10:,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.3126e+01,  7.0347e+01, -1.0076e+01],\n",
              "        [-1.0572e+01,  2.7790e+01,  1.8030e+01],\n",
              "        [-1.9625e+00,  5.8161e+00,  2.8308e+00],\n",
              "        [ 9.4442e-02,  5.6617e-01, -8.0060e-01],\n",
              "        [ 1.4751e+00,  1.1778e-01,  1.1701e+00],\n",
              "        [ 3.4894e+01,  3.0397e+01, -6.7366e+00],\n",
              "        [ 4.0253e+00,  5.8051e+00, -2.0695e+00],\n",
              "        [ 2.6350e+02,  4.5084e+01,  8.0810e+01],\n",
              "        [ 6.1699e+00,  1.8057e+01,  5.8050e+00],\n",
              "        [-6.3174e+00, -2.1244e+01,  4.0846e+01]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpQt_GNeJCQq"
      },
      "source": [
        "ypred = torch.argmax(ypred, dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7q_2LhEqgoH"
      },
      "source": [
        "ypred = ypred.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf8SIiOHJxoH"
      },
      "source": [
        "yte = yte.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J3M3tEVJ9y7",
        "outputId": "d256cbd0-11da-441b-c92d-bda12f1bed5a"
      },
      "source": [
        "np.sum(ypred == yte)/len(yte)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5315553745928339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDnJW6eXmT4t"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VSqwoHaUU4z",
        "outputId": "9bf6f148-e392-4318-9981-9361a8503f18"
      },
      "source": [
        "a = np.array([[1,2,3], [4,5,6]])\n",
        "b = np.array([[7,8,9], [10,11,12]])\n",
        "np.concatenate((a,b))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3],\n",
              "       [ 4,  5,  6],\n",
              "       [ 7,  8,  9],\n",
              "       [10, 11, 12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOKjLhDhmVTZ"
      },
      "source": [
        "def create_dataset_for_sequence(df, dct, emb_dim = 300, seq_len = 20):\n",
        "  sequence_matrix = np.zeros((df.shape[0], seq_len*2 ,emb_dim))\n",
        "  hit = 0\n",
        "  miss = 0\n",
        "  for i, (s1, s2) in enumerate(zip(df['sentence1'], df['sentence2'])):\n",
        "    vec1 = np.zeros((seq_len, emb_dim))\n",
        "    vec2 = np.zeros((seq_len, emb_dim))\n",
        "    s1 = s1.lower()\n",
        "    s2 = s2.lower()\n",
        "    s1 = word_tokenize(s1)\n",
        "    s2 = word_tokenize(s2)\n",
        "    for j, (w1, w2) in enumerate(list(itertools.zip_longest(s1, s2, fillvalue='foo'))):\n",
        "      if j>= seq_len:\n",
        "        break\n",
        "      if w1 != \"foo\":\n",
        "        check1 = dct.get(w1)\n",
        "        if check1 is not None:\n",
        "          vec1[j, :] = check1\n",
        "          hit+=1\n",
        "        else:\n",
        "          miss+=1\n",
        "        \n",
        "      if w2 != \"foo\":\n",
        "        check1 = dct.get(w2)\n",
        "        if check1 is not None:\n",
        "          vec2[j, :] = check1\n",
        "          hit+=1\n",
        "        else:\n",
        "          miss+=1\n",
        "    ##\n",
        "    # vec1 = np.asarray(vec1)\n",
        "    # vec2 = np.asarray(vec2)\n",
        "    # if func == \"sum\":\n",
        "    #   vec1 = np.sum(vec1, axis = 0)\n",
        "    #   vec2 = np.sum(vec2, axis = 0)\n",
        "    # if func == \"mean\":\n",
        "    #   vec1 = np.mean(vec1, axis = 0)\n",
        "    #   vec2 = np.mean(vec2, axis = 0)\n",
        "    #print(\"vec1 \", vec1.shape, \"vec2 shape \", vec2.shape, \"i is \", i)\n",
        "    sequence_matrix[i, :, :] = np.concatenate((vec1, vec2))\n",
        "  ##\n",
        "  print(f\"The number of hits are {hit} and the number of miss are {miss}\")\n",
        "  labels = df['labels'].values\n",
        "  return sequence_matrix, labels    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNvj9omv0ujx"
      },
      "source": [
        "class Mylstm(nn.Module):\n",
        "  def __init__(self, batch_size, hidden_size, num_classes, num_layers, embedding_dim):\n",
        "    super(Mylstm, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_classes = num_classes\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.lstm = nn.LSTM(input_size= self.embedding_dim, hidden_size= self.hidden_size, num_layers = self.num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
        "    \n",
        "\n",
        "  # def forward(self, x):\n",
        "  #   out, (self.h0, self.c0) = self.lstm(x, (self.h0, self.c0))\n",
        "  #   out = self.fc(out[:,-1,:])\n",
        "  #   return out\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, (self.h0, self.c0) = self.lstm(x, (self.h0, self.c0))\n",
        "    # out = out.contiguous().view(-1, self.hidden_size)\n",
        "    tmp = out.clone()\n",
        "    tmp = out[:, -1, :]\n",
        "    #out = out[:,-1,:]\n",
        "    #out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
        "    out = self.fc(tmp)\n",
        "    return out\n",
        "\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    self.h0 = torch.rand(1, self.batch_size, self.hidden_size)\n",
        "    self.c0 = torch.rand(1, self.batch_size, self.hidden_size)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox_Oldf404eE"
      },
      "source": [
        "def train_lstm(model, seq, labels, epochs = 10, lr = 0.005, batch_size = 461, hidden_size = 2):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "  l = []\n",
        "  for epoch in range(epochs):\n",
        "    model.init_hidden()\n",
        "    for i in range(batch_size, seq.shape[0], batch_size):\n",
        "      model.zero_grad()\n",
        "      xtrain = seq[i-batch_size: i,:,:]\n",
        "      target = labels[i-batch_size: i]\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out= model(xtrain)\n",
        "      loss = criterion(out, target)\n",
        "      print(\"\")\n",
        "      print(\"Loss here : \", loss.item())\n",
        "      l.append(loss)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      # hidden[0].detach()\n",
        "      # hidden[1].detach()\n",
        "    print(\"loss is \", l[:5])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykam_U3M8MZW",
        "outputId": "9e01e40b-9799-4735-a162-13b7f4de7a04"
      },
      "source": [
        "dct = Embedding_dict(\"/content/glove.6B.300d.txt\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words found are 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQhgUIkY8OFY",
        "outputId": "c34cb24c-2a1e-4440-e49c-dbe51fee1f3f"
      },
      "source": [
        "df_test = df.head(100)\n",
        "df_test, label = create_dataset_for_sequence(df_test, dct)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of hits are 2358 and the number of miss are 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iBNHvJc87J2"
      },
      "source": [
        "df_test = torch.tensor(df_test).float()\n",
        "label = torch.tensor(label).type(torch.LongTensor)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqU1w1Wh89de"
      },
      "source": [
        "model = Mylstm(batch_size= 1, hidden_size= 128, num_classes= 3, num_layers= 1, embedding_dim= 300)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_SsalfR-l6G",
        "outputId": "133ced5d-42e8-410f-cde1-d25199407a40"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 40, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "HRTKJgi99QeA",
        "outputId": "b8ff78fc-e4c3-44e4-bd9b-7e988c3aed0f"
      },
      "source": [
        "train_lstm(model, df_test, label, batch_size=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain shape  torch.Size([1, 40, 300])\n",
            "\n",
            "Loss here :  0.9972867965698242\n",
            "xtrain shape  torch.Size([1, 40, 300])\n",
            "\n",
            "Loss here :  1.191184163093567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5861c075056f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-dee6389895e4>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(model, seq, labels, epochs, lr, batch_size, hidden_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss here : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m# hidden[0].detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 512]], which is output 0 of TBackward, is at version 3; expected version 2 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FglHawZg9vds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}